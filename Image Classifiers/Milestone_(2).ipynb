{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Esmtra/Computational_Intelligence-Optimization-Image_Classifiers-/blob/main/Milestone_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-5pIcQ4YDTy"
      },
      "source": [
        "\n",
        "**Team Names**\n",
        "\n",
        "Eslam Sayed Rady                                                                   1902236  \n",
        "Mohamed Hussein Adel                                                        1802683\n",
        "\n",
        "Abdelrahman Adel Saeed                                                     1805626\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dS4qgLoYAOh"
      },
      "source": [
        "***   Over View   ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhB6gi_IYfee"
      },
      "source": [
        "It's a major task for Computational Intelligence course 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP2gAFiNY7Ca"
      },
      "source": [
        "Second milestone : The aim of this project is to create and train a multilayer Neural Network to\n",
        "classify an image into its corresponding category.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "MHtLLZ_QtZtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wxW58Nk3upmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Configuration\n"
      ],
      "metadata": {
        "id": "lNk723m8uvWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 50\n",
        "IMG_WIDTH, IMG_HEIGHT, IMG_NUM_CHANNELS = 32, 32, 3\n",
        "LOSS_FUNCTION = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "NUM_CLASSES = 10\n",
        "NUM_EPOCHS = 100\n",
        "OPTIMIZER = optimizers.Adam()\n",
        "VALIDATION_SPLIT = 0.2\n",
        "VERBOSITY = 1\n"
      ],
      "metadata": {
        "id": "YIH6dzGWu1Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CIFAR-10 data\n"
      ],
      "metadata": {
        "id": "N1tKEE6Ru3ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "yInpc3XXu9ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determine shape of the data"
      ],
      "metadata": {
        "id": "lC8NtnHCvBem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, IMG_NUM_CHANNELS)\n"
      ],
      "metadata": {
        "id": "o_RJloo2vF_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse numbers as floats\n"
      ],
      "metadata": {
        "id": "Gn_CSRkJvJpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n"
      ],
      "metadata": {
        "id": "RC1K0UHWvNzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize data\n"
      ],
      "metadata": {
        "id": "pmKimaY-vVDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_train = input_train / 255\n",
        "input_test = input_test / 255"
      ],
      "metadata": {
        "id": "pIAMifC6vXiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the model\n"
      ],
      "metadata": {
        "id": "bJAxtz8XvaZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer with 32 filters, a kernel size of (3, 3), and ReLU activation\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# First max pooling layer with a pool size of (2, 2)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Second convolutional layer with 64 filters, a kernel size of (3, 3), and ReLU activation\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "# Second max pooling layer with a pool size of (2, 2)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Third convolutional layer with 128 filters, a kernel size of (3, 3), and ReLU activation\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "# Third max pooling layer with a pool size of (2, 2)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten layer reshape the output to 1-D array\n",
        "model.add(Flatten())\n",
        "\n",
        "# First fully connected layer with 256 neurons and ReLU activation\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Second fully connected layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Output layer with NUM_CLASSES neurons and softmax activation\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax'))"
      ],
      "metadata": {
        "id": "ywFC0xJqvd7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the model"
      ],
      "metadata": {
        "id": "vsaKuRsLvhUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=LOSS_FUNCTION,\n",
        "              optimizer=OPTIMIZER,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "puMJYBDOvj-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit data to model"
      ],
      "metadata": {
        "id": "o_XcCFzkvmNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(input_train, target_train,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            verbose=VERBOSITY,\n",
        "            validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rm8RfJ7voL0",
        "outputId": "619901d9-cd29-4fd0-ad7e-b2292050a852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 66s 81ms/step - loss: 1.6018 - accuracy: 0.4065 - val_loss: 1.3212 - val_accuracy: 0.5197\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 1.2082 - accuracy: 0.5687 - val_loss: 1.1219 - val_accuracy: 0.6097\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 1.0333 - accuracy: 0.6352 - val_loss: 1.0059 - val_accuracy: 0.6482\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.9122 - accuracy: 0.6790 - val_loss: 0.9253 - val_accuracy: 0.6808\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.8152 - accuracy: 0.7122 - val_loss: 0.9064 - val_accuracy: 0.6874\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 64s 79ms/step - loss: 0.7445 - accuracy: 0.7372 - val_loss: 0.9089 - val_accuracy: 0.6871\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.6722 - accuracy: 0.7663 - val_loss: 0.8922 - val_accuracy: 0.6935\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.6125 - accuracy: 0.7845 - val_loss: 0.8957 - val_accuracy: 0.6967\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.5544 - accuracy: 0.8051 - val_loss: 0.9482 - val_accuracy: 0.6925\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.4996 - accuracy: 0.8259 - val_loss: 0.9299 - val_accuracy: 0.7074\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.4490 - accuracy: 0.8406 - val_loss: 0.9422 - val_accuracy: 0.7118\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.4097 - accuracy: 0.8562 - val_loss: 1.0204 - val_accuracy: 0.6989\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.3690 - accuracy: 0.8681 - val_loss: 1.0042 - val_accuracy: 0.7091\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.3279 - accuracy: 0.8834 - val_loss: 1.1063 - val_accuracy: 0.7005\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.2897 - accuracy: 0.8964 - val_loss: 1.1806 - val_accuracy: 0.7053\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.2712 - accuracy: 0.9040 - val_loss: 1.2936 - val_accuracy: 0.6981\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.2294 - accuracy: 0.9169 - val_loss: 1.4282 - val_accuracy: 0.7015\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.2136 - accuracy: 0.9239 - val_loss: 1.3345 - val_accuracy: 0.7048\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.1937 - accuracy: 0.9319 - val_loss: 1.3895 - val_accuracy: 0.7012\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.1853 - accuracy: 0.9336 - val_loss: 1.5076 - val_accuracy: 0.7021\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.1623 - accuracy: 0.9431 - val_loss: 1.5254 - val_accuracy: 0.7107\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.1562 - accuracy: 0.9436 - val_loss: 1.6374 - val_accuracy: 0.7035\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.1583 - accuracy: 0.9434 - val_loss: 1.7118 - val_accuracy: 0.6938\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 64s 79ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 1.7847 - val_accuracy: 0.7038\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 65s 82ms/step - loss: 0.1315 - accuracy: 0.9535 - val_loss: 1.8045 - val_accuracy: 0.6952\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 62s 77ms/step - loss: 0.1229 - accuracy: 0.9574 - val_loss: 1.8548 - val_accuracy: 0.6974\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.1159 - accuracy: 0.9587 - val_loss: 1.8515 - val_accuracy: 0.7042\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 1.8792 - val_accuracy: 0.6997\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 62s 77ms/step - loss: 0.1163 - accuracy: 0.9602 - val_loss: 1.9218 - val_accuracy: 0.7011\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.1106 - accuracy: 0.9626 - val_loss: 1.9328 - val_accuracy: 0.6987\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 67s 84ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 2.0350 - val_accuracy: 0.7046\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 67s 83ms/step - loss: 0.1149 - accuracy: 0.9607 - val_loss: 1.9573 - val_accuracy: 0.7073\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 64s 79ms/step - loss: 0.1079 - accuracy: 0.9625 - val_loss: 1.9584 - val_accuracy: 0.7022\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0996 - accuracy: 0.9663 - val_loss: 2.0805 - val_accuracy: 0.7047\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0913 - accuracy: 0.9694 - val_loss: 2.0578 - val_accuracy: 0.6946\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.1070 - accuracy: 0.9658 - val_loss: 2.1132 - val_accuracy: 0.6973\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0825 - accuracy: 0.9724 - val_loss: 2.1857 - val_accuracy: 0.7050\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 2.2887 - val_accuracy: 0.7008\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.1009 - accuracy: 0.9669 - val_loss: 2.1454 - val_accuracy: 0.7029\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 66s 82ms/step - loss: 0.0821 - accuracy: 0.9725 - val_loss: 2.2332 - val_accuracy: 0.6975\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 66s 83ms/step - loss: 0.1080 - accuracy: 0.9642 - val_loss: 2.1741 - val_accuracy: 0.7020\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0617 - accuracy: 0.9798 - val_loss: 2.3808 - val_accuracy: 0.6977\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0957 - accuracy: 0.9680 - val_loss: 2.2344 - val_accuracy: 0.6992\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0842 - accuracy: 0.9721 - val_loss: 2.2723 - val_accuracy: 0.6969\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0807 - accuracy: 0.9737 - val_loss: 2.2169 - val_accuracy: 0.7005\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0742 - accuracy: 0.9757 - val_loss: 2.4947 - val_accuracy: 0.7012\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0864 - accuracy: 0.9717 - val_loss: 2.2981 - val_accuracy: 0.7004\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 2.4826 - val_accuracy: 0.6987\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 67s 83ms/step - loss: 0.0812 - accuracy: 0.9734 - val_loss: 2.3686 - val_accuracy: 0.6968\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0785 - accuracy: 0.9739 - val_loss: 2.5228 - val_accuracy: 0.6914\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0727 - accuracy: 0.9752 - val_loss: 2.5387 - val_accuracy: 0.6973\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0712 - accuracy: 0.9769 - val_loss: 2.4774 - val_accuracy: 0.6999\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0792 - accuracy: 0.9740 - val_loss: 2.4536 - val_accuracy: 0.7036\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0729 - accuracy: 0.9773 - val_loss: 2.4586 - val_accuracy: 0.6966\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 2.6870 - val_accuracy: 0.6972\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0811 - accuracy: 0.9734 - val_loss: 2.5257 - val_accuracy: 0.7022\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0669 - accuracy: 0.9786 - val_loss: 2.5084 - val_accuracy: 0.7060\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 2.5526 - val_accuracy: 0.6992\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 2.6551 - val_accuracy: 0.6927\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0643 - accuracy: 0.9790 - val_loss: 2.6427 - val_accuracy: 0.6927\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0697 - accuracy: 0.9775 - val_loss: 2.4799 - val_accuracy: 0.7022\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 64s 81ms/step - loss: 0.0643 - accuracy: 0.9788 - val_loss: 2.6240 - val_accuracy: 0.6967\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0616 - accuracy: 0.9799 - val_loss: 2.7065 - val_accuracy: 0.6988\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0730 - accuracy: 0.9774 - val_loss: 2.7108 - val_accuracy: 0.6999\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0640 - accuracy: 0.9793 - val_loss: 2.7073 - val_accuracy: 0.6986\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 64s 79ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 2.6871 - val_accuracy: 0.7038\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0618 - accuracy: 0.9798 - val_loss: 2.7342 - val_accuracy: 0.6988\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0585 - accuracy: 0.9813 - val_loss: 2.7387 - val_accuracy: 0.7040\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 2.7420 - val_accuracy: 0.6989\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0611 - accuracy: 0.9799 - val_loss: 2.7602 - val_accuracy: 0.6938\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 64s 81ms/step - loss: 0.0597 - accuracy: 0.9806 - val_loss: 2.7855 - val_accuracy: 0.6991\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0616 - accuracy: 0.9801 - val_loss: 3.0105 - val_accuracy: 0.6891\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0604 - accuracy: 0.9806 - val_loss: 2.9791 - val_accuracy: 0.6862\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0669 - accuracy: 0.9799 - val_loss: 2.8233 - val_accuracy: 0.7002\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0592 - accuracy: 0.9805 - val_loss: 2.7780 - val_accuracy: 0.6959\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 2.8851 - val_accuracy: 0.7017\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 2.7641 - val_accuracy: 0.7029\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 64s 80ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 2.8894 - val_accuracy: 0.6986\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0597 - accuracy: 0.9818 - val_loss: 2.8781 - val_accuracy: 0.6924\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0495 - accuracy: 0.9850 - val_loss: 2.9539 - val_accuracy: 0.6961\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 66s 82ms/step - loss: 0.0626 - accuracy: 0.9804 - val_loss: 2.7775 - val_accuracy: 0.7026\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0567 - accuracy: 0.9822 - val_loss: 3.0397 - val_accuracy: 0.6984\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 2.8420 - val_accuracy: 0.6987\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 65s 81ms/step - loss: 0.0564 - accuracy: 0.9826 - val_loss: 2.9689 - val_accuracy: 0.7049\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0542 - accuracy: 0.9831 - val_loss: 2.9612 - val_accuracy: 0.7032\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0554 - accuracy: 0.9835 - val_loss: 2.9510 - val_accuracy: 0.7011\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 66s 83ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 2.9474 - val_accuracy: 0.7001\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0545 - accuracy: 0.9839 - val_loss: 2.9672 - val_accuracy: 0.6997\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 2.9775 - val_accuracy: 0.6938\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 66s 82ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 2.9561 - val_accuracy: 0.7015\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 2.9509 - val_accuracy: 0.6980\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 2.8627 - val_accuracy: 0.6919\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 66s 82ms/step - loss: 0.0467 - accuracy: 0.9852 - val_loss: 3.1051 - val_accuracy: 0.6920\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 63s 79ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 3.0386 - val_accuracy: 0.6992\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 62s 77ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 2.9129 - val_accuracy: 0.6918\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 66s 82ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 3.0665 - val_accuracy: 0.6961\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0533 - accuracy: 0.9837 - val_loss: 3.0744 - val_accuracy: 0.6844\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 63s 78ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 3.0106 - val_accuracy: 0.7012\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 65s 82ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 3.0266 - val_accuracy: 0.7063\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 62s 78ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 3.0320 - val_accuracy: 0.6958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate generalization metrics"
      ],
      "metadata": {
        "id": "VXjtRojivpi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]:.4f} / Test accuracy: {score[1]:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrz2jFEMvtND",
        "outputId": "f6a927ff-bd8c-4e5f-860e-e06184d46b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 3.1205 / Test accuracy: 0.6879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize history"
      ],
      "metadata": {
        "id": "rXTvjkJjvwsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "CrHa8NgmunIw",
        "outputId": "75f2f2f4-dd18-4954-e2f6-59b70b76da46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOk1np/W7nmnJxlCxFRIPt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}